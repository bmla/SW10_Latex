% !TEX root = ../paper.tex
\section{Related work} \label{sec:relatedwork}
In this section we present related work which has been done in the area of techniques for transferring information and data between mobile devices and displays.
We also present developments within the topics of pointing in mid-air and controlling a cursor on a display at a distance.

\subsection{Large displays \& Mid-air pointing} \label{sec:largeDisplayAirPointing}
The interaction techniques for large displays most commonly used are touch and mid-air pointing.
For pointing in mid-air there are different technologies such as Microsoft Kinect and Microsofts's new mixed reality glasses, named HoloLens.
With HoloLens, the controlling interface is hand gestures combining the physical 3D world with the virtual or augmented reality made possible with the HoloLens.
Using mid-air gestures can also make the physical space we move around in combine more seamlessly with what we see on a large display.

% Talk about Put-That-There (that old paper from 1984)
In 1984, Bolt \cite{Bolt:1980} demonstrated a system utilizing voice recognition and gesture input for creating, moving, deleting, and  manipulating objects on a large screen.
The system combines the two technologies and creates an interface capable of receiving voice commands i.e. \textit{``Create a blue square''}  and coupling it with a pointing gesture and the word \textit{``there''}.

% This is the Off-Limits paper
Using a large display and mid-air pointing, Markussen et al. \cite{Markussen:2016} explored an interaction concept called \emph{Off-Limits} in which the user is able to interact with a large display outside the boundaries of the screen.
The results show that, for off-screen interaction, touch is slower than using mid-air techniques but participants who used mid-air would undershoot their targets.
This problem resulted in a model that corrects for undershooting thus creating a better mapping between where participants would like to point and where they actually point.
The study showed that \emph{Off-Limits} outperformed the naive implementation of an off-screen technique by being faster and requiring fewer interactions.
%Participants had to acquire a number by pointing on a horizontal line that continued beyond the screen's boundary in both directions.
%They did three studies and in the first two they were exploring the performance and how people understand off-screen space.
%For the last experiment they compared the \emph{Off-Limits} interface (which was created based on knowledge from two previous studies) with the na√Øve implementation of \emph{Off-Screen} pointing.

% Should I Stay or Should I Go
Jacobsen et al. \cite{Jakobsen:2015} explore two different interaction interfaces for large displays, namely touch and mid-air gestures.
With two experiments they aim to find out when users choose one interface over the other.
The first experiment aims to compare touch and mid-air gestures and the results showed a high error rate for both, while the target selection time for mid-air was 40\% more than for touch.
Participants were given questions on subjective satisfaction and the results showed that 12 of 19 preferred touch and 7 of 19 preferred mid-air.
I a second experiment users were free to choose which interface to use and during the experiment physical movements were required to simulate circumstances where it would be necessary to move away from the screen.
The results revealed that in 42\% of the trials made, participants chose to use mid-air gestures and that for medium to large target sizes where users were asked to move to and from the display, mid-air was used more often than touch.
With 7 out of 10 participants preferring mid-air gestures for the second experiment, the cost of moving back and forth to use the touch interface would seem to make mid-air pointing preferable.

% Code Space
Bragdon et al. \cite{Bragdon:2011} created a system called Code Space to support developer meetings.
The system uses cross-device interaction techniques for people to interactively participate and contribute to meetings by using hand gestures to point at and manipulate the content on the shared screen.
They also use their handhelds and laptops to push and pull content to and from the shared screen.
Techniques for manipulating objects include mid-air finger pointing and also mid-air phone pointing to move objects on the screen.
Techniques for sharing objects include pointing with the phone and swiping to push and pull objects to and from the shared display.
Another technique is transient sharing from e.g. a handheld device, which is performed by holding the device's screen perpendicular with the floor to share an object.
A pilot evaluation was conducted and feedback from the participants indicated an overall positive attitude towards the system with comments such as \textit{``this is awesome'', ``cool'', ``this is Minority Report stuff, I love it'', ``everyone can participate''.}
Also, participants generally felt that the interactions were socially acceptable to perform within their team of fellow developers.

\subsection{Target acquisition using hands} \label{sec:targetAcquisitionHands}
% Ray casting with Mayer et al. Modeling Distant Pointing for Compensating Systematic Displacements
% and Vogel et al. Distant Freehand Pointing and Clicking on Very Large, High Resolution Displays 
In the literature, research on different approaches to pointing and controlling e.g virtual pointers on a screen using hands and fingers has been done by Mayer et al. \cite{Mayer:2015} and Vogel et al. \cite{Vogel:2005} among others.
Mayer et al. presents a study on 3 techniques for absolute distant pointing without visual feedback to see how precise participants were with the three techniques and if the precision could be improved.
They found that for the most precise technique (\emph{index finger ray casting}) the average error was 61.3 cm before applying a correction model.
Using a correction model on the same technique they found that the average error could be reduced by 37.3\% for both sitting and standing at different distances from the display.
This means that pointing techniques without visual feedback can benefit greatly from correction models.
Vogel et al. experimented with three pointing techniques to acquire targets on a very large display with high resolution and their findings show that a \emph{RayCasting} technique (extends a ray from the index finger) is significantly faster than two other techniques, \emph{Relative} and \emph{RayToRelative} (a combination of \emph{RayCasting} and \emph{Relative}).
In contrast, error rates are far lower for the two relative techniques and the largest difference between \emph{RayCasting} and the relative techniques are for medium to small target sizes indicating that \emph{RayCasting} is less accurate for smaller targets.

% Investigating Intuitiveness and Effectiveness of Gestures for Free Spatial Interaction with Large Displays
Hespanhol et al. \cite{Hespanhol:2012} proposes a set of five mid-air gestures to perform selections and rearrange items on a large display using only hands.
Each of their gestures are described with a scenario in which a given gesture is commonly used e.g. a \emph{push} gesture for pressing a button or a \emph{grab} gesture with the scenario of grabbing a physical object which can then also be moved around.
Results showed that \emph{dwelling} and \emph{grabbing} were the two fastest gestures for selecting and rearranging respectively and they were also the two gestures with the lowest amount of failures for both tasks.

\subsection{Target acquisition using handheld devices} \label{sec:midAirPointingHandheld}
% Scroll, tilt or move it
Boring et al. \cite{Boring:2009} experimented with using mobile phones to control a cursor on large displays with three different interaction techniques to move the cursor.
The three techniques were \emph{Scroll} (using buttons on the phone to move pointer), \emph{Tilt} (tilting the phone to move pointer), and \emph{Move} (moving the phone in a direction to move the pointer in the same direction).
In the experiment each technique was tested and participants had to acquire a number of targets with long or short distances between them and with three different target sizes to hit.
Results showed that for both larger target sizes and smaller distances the selection times were lower while the fastest technique for both distance and size were \emph{Move}.
For error rates, the results show that short distances and larger target sizes reduce the error rate while the technique with lowest error rate was \emph{Scroll}.
Questionnaires showed that for general comfort there was no trend towards any single technique but \emph{Scroll} was significantly ``easier to use'' than \emph{Tilt}, which participants seemed frustrated using.

% This one is about pointing techniques where they are using handdeld devices (both smartphones and tablests)
A study by Nancel et al. \cite{Nancel:2013} focuses on using handheld devices and high precision pointing techniques for acquiring targets on a large wall sized display.
Their implementation uses the handheld device for controlling the pointer on the large display and a small area of the handheld device is used for relative pointing.
One technique uses two fingers for coarse pointing and one finger for precision pointing. 
Another technique uses a head-based coarse pointing technique making it possible for the participants to roughly get the pointer close to the target using their head.
They found that continuous head pointing is faster and more successful than their other techniques.
A comparison showed that their technique performed as good as some state-of-the-art techniques such as LaserGyro\cite{Vogel:2005} and SmoothPoint\cite{Gallo:2012}. 
They showed that it was in fact possible to maintain precision and ample screen real estate on the handheld device.
%The two techniques both have a discrete and a continuous mode giving a total of 4 techniques that were compared with each other and two techniques were also compared to two state-of-the-art techniques, LaserGyro (based on \cite{Vogel:2005}) and SmoothPoint \cite{Gallo:2012}.

Rashid et al. \cite{Rashid:2011} explore two different techniques for interacting with and acquiring targets on a large display using a handheld device.
The first technique is \emph{Proximal Selection (PS)} which pulls a selected, or zoomed in, area of the large display onto the phone and the user is then able to select the correct target.
The second technique is \emph{Distal Selection (DS)} where the user points at the large display, zooms in on the selected area, and finally selects the desired target on the large display.
In their experiment they found that, for complex tasks and with regards to time, \emph{PS} outperforms \emph{DS} but for simpler tasks \emph{DS} was approximately 0.1 seconds faster but the effect was not significant.
The error rate for the techniques showed that \emph{DS} had fewer missed clicks for both small and large targets and that \emph{DS} had a significantly lower error rate than \emph{PS} only for small targets.

\subsection{Data transfer \& Interaction using handheld devices} \label{sec:targetAcquisition}
Techniques for interacting with large displays using a handheld devices are numerous and includes smartphones, gyro mice, game controllers (both with and without gyroscopes and accelerometers), and devices fitted with lasers.
% Myers et al.: Interacting at a Distance: Measuring the Performance of Laser pointers and Other Devices
Mid-Air pointing in the beginning of the 21st century used laser pointers etc. to interact with and select objects on large displays from a distance. 
Myers et al. \cite{Myers:2002} experimented with laser pointers and for target acquisition and measured time, accuracy, and how good participants were to dwell on a target using the different lasers.
They tested four devices (2 laser pointer, 1 Palm PC fitted with a laser, and 1 toy gun fitted with a laser) and different ways to hold them. 
The results showed that holding the Palm PC with one and two hands were the most stable but the Palm PC was also the one users found most cumbersome and heavy. 
They also did an experiment comparing 4 ways of selecting objects on a large display.
The technique with the fastest selection time and the lowest error rate was touching directly on the SmartBoard used in the experiment and the laser pointer was slowest and had the second highest error rate.
Based on the results, a suggestion was made to explore combining laser pointers with other techniques and use the laser to make a coarse grained selection and other techniques as the fine grained selection.

% Baudisch et al.: Soap: a Pointing Device that Works in Mid-Air
% Need to read the 4 pages before we can write something on this little device :D
One of the earlier examples of transferring data using handheld devices is presented by Rekimoto \cite{}. 
The system presented is called \textit{Pick-and-Drop} and revolves around a handheld display and a pen capable of picking up objects on one device and transferring it to another device.
The ``Pick-and-Drop'' metaphor is closely related to real world objects where, for example, a piece of paper is picked up from one table and placed on another table.
Another implementation uses wall-sized displays as a common workplace for participants and the interaction between participants' PDAs and the wall-sized display would use \textit{Pick-and-Drop}.

Approaches to transferring data by gesturing with handheld device have been documented in the literature and amongst them are throw and tilt gestures using handheld devices for interacting with large displays.
Dachselt et al. \cite{Dachselt:2008} and Boring et al. \cite{Boring:2009} describe how a tilt technique with a handheld phone can be used to control a pointer on a remote display.
In addition, Dachselt et al. describe a throwing gesture for transferring data (e.g. from a phone) to and from a large display and the application proposed also uses the concept of transferring an entire user interface between a phone and a display using the throw gesture.
The idea behind transferring the entire interface is to allow seamless interaction between large display and phone and subsequently improve usability (phone to display) or mobility (display to phone).