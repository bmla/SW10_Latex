% !TEX root = ../paper.tex
\section{Introduction} \label{sec:introduction}
In line with technological advances, single screen digital displays, for both domestic and public use, are available in increasingly larger sizes than just a few years ago.
It has been shown that interacting with systems that use these large displays benefit from using mid-air pointing, making it possible to use hands to navigate around the screen from a distance (ref: paper on touch vs mid-air).
Mid-air interactions are being increasingly used for different applications, e.g., in gaming or virtual and augmented reality.
Consumer depth cameras, like the popular Microsoft Kinect, have been around for years and allow users to control a game using mid-air gestures.
The Kinect has also been popular with researchers who have used them to explore new interfaces for applications and new human computer interaction possibilities, e.g., mid-air pointing or bodily movement to communicate with the system.

If we introduce a smartphone into this mid-air pointing and large display mix, we enable the transfer of information to and from the display, e.g., text, videos, images and other media, between the smartphone and the system.
But how do we decide which interaction techniques people should use with their mobile devices to make the transfer happen? Different kinds of mid-air techniques have been studied in different situations in the literature but we have not found any existing empirical research that compares alternative mid-air techniques using smartphones for two-way interaction with large displays.
An understanding of how different techniques compare with each other in terms of effectiveness, efficiency and accuracy could help interaction designers make decisions about which interactions to implement in their systems.
Interactions to support users pushing or pulling information between the system and their mobile devices could be designed based on which of these attributes is most important in a particular application context.
Another important aspect for interaction designers could be the “naturalness” or learnability of the alternative mid-air techniques, which would also influence their choice of technique.

To contribute to current knowledge on these issues, we have conducted an empirical study that compared and analyzed the data collected from an experiment on 8 different interaction techniques, that is, 4 techniques for push (from smartphone to display) and 4 techniques for pull (from display to smartphone).
By comparing these techniques on parameters of hit rate, time taken, and distance from target, with two experiments in a controlled environment, we are able to demonstrate which techniques are more precise than others and which are faster in a laboratory setting.

In the first experiment, with 51 participants, we collect data to compare time and hit rate for each technique, while in the second experiment, with 33 participants, we collected data to compare techniques on accuracy.
In this paper we report on our findings from this experiment, showing that for pushing data to the screen, a grabbing gesture on the touch screen of the phone is most effective and a swiping gesture is second.
However, for pulling data from the screen, this is reversed for their symmetrically opposite gestures.
Here the most effective is a swipe on the phones screen, and a backwards throw (or catch) is second.
This also shows that a two handed gesture was better for pushing data, and a single handed gesture was better for pulling it, in terms of our measured parameters.